{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "* 20190102: \n",
    "    * Predict stock price in next day using long short term memory(LSTM)\n",
    "    * Given prices for the last N days, we do prediction for day N+1\n",
    "    * Here we split 3 years of data into train(60%), dev(20%) and test(20%)\n",
    "* 20190120 - Diff from SotckPricePrediction_v4_lstm.ipynb: \n",
    "    * Instead of MinMaxScaler, here we use StandardScaler\n",
    "    * Instead of using the same mean and variance to do scaling for train, dev and test sets, we scale the train set to have mean 0 and var 1, and then whenever we do prediction on dev or test set we scale the previous N values to also have mean 0 and var 1 (ie. use the means and variances of the previous N values to do scaling. We do this for both feature columns and target columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from datetime import date\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import seed\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import plot_model\n",
    "#### Input params ##################\n",
    "stk_path = \"./data/VTI.csv\"\n",
    "test_size = 0.2                # proportion of dataset to be used as test set\n",
    "cv_size = 0.2                  # proportion of dataset to be used as cross-validation set\n",
    "\n",
    "N = 9                          # for feature at day t, we use lags from t-1, t-2, ..., t-N as features. \n",
    "                               # initial value before tuning\n",
    "lstm_units=50                  # lstm param. initial value before tuning.\n",
    "dropout_prob=1                 # lstm param. initial value before tuning.\n",
    "optimizer='adam'               # lstm param. initial value before tuning.\n",
    "epochs=1                       # lstm param. initial value before tuning.\n",
    "batch_size=1                   # lstm param. initial value before tuning.\n",
    "\n",
    "model_seed = 100\n",
    "\n",
    "fontsize = 14\n",
    "ticklabelsize = 14\n",
    "####################################\n",
    "\n",
    "# Set seeds to ensure same output results\n",
    "seed(101)\n",
    "tensorflow.random.set_seed(model_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_mape(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Compute mean absolute percentage error (MAPE)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def get_x_y(data, N, offset):\n",
    "    \"\"\"\n",
    "    Split data into x (features) and y (target)\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "    for i in range(offset, len(data)):\n",
    "        x.append(data[i-N:i])\n",
    "        y.append(data[i])\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def get_x_scaled_y(data, N, offset):\n",
    "    \"\"\"\n",
    "    Split data into x (features) and y (target)\n",
    "    We scale x to have mean 0 and std dev 1, and return this.\n",
    "    We do not scale y here.\n",
    "    Inputs\n",
    "        data     : pandas series to extract x and y\n",
    "        N\n",
    "        offset\n",
    "    Outputs\n",
    "        x_scaled : features used to predict y. Scaled such that each element has mean 0 and std dev 1\n",
    "        y        : target values. Not scaled\n",
    "        mu_list  : list of the means. Same length as x_scaled and y\n",
    "        std_list : list of the std devs. Same length as x_scaled and y\n",
    "    \"\"\"\n",
    "    x_scaled, y, mu_list, std_list = [], [], [], []\n",
    "    for i in range(offset, len(data)):\n",
    "        mu_list.append(np.mean(data[i-N:i]))\n",
    "        std_list.append(np.std(data[i-N:i]))\n",
    "        x_scaled.append((data[i-N:i]-mu_list[i-offset])/std_list[i-offset])\n",
    "        y.append(data[i])\n",
    "    x_scaled = np.array(x_scaled)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x_scaled, y, mu_list, std_list\n",
    "\n",
    "def train_pred_eval_model(x_train_scaled, \\\n",
    "                          y_train_scaled, \\\n",
    "                          x_cv_scaled, \\\n",
    "                          y_cv, \\\n",
    "                          mu_cv_list, \\\n",
    "                          std_cv_list, \\\n",
    "                          lstm_units=50, \\\n",
    "                          dropout_prob=0.5, \\\n",
    "                          optimizer='adam', \\\n",
    "                          epochs=1, \\\n",
    "                          batch_size=1):\n",
    "    '''\n",
    "    Train model, do prediction, scale back to original range and do evaluation\n",
    "    Use LSTM here.\n",
    "    Returns rmse, mape and predicted values\n",
    "    Inputs\n",
    "        x_train_scaled  : e.g. x_train_scaled.shape=(451, 9, 1). Here we are using the past 9 values to predict the next value\n",
    "        y_train_scaled  : e.g. y_train_scaled.shape=(451, 1)\n",
    "        x_cv_scaled     : use this to do predictions \n",
    "        y_cv            : actual value of the predictions\n",
    "        mu_cv_list      : list of the means. Same length as x_scaled and y\n",
    "        std_cv_list     : list of the std devs. Same length as x_scaled and y \n",
    "        lstm_units      : lstm param\n",
    "        dropout_prob    : lstm param\n",
    "        optimizer       : lstm param\n",
    "        epochs          : lstm param\n",
    "        batch_size      : lstm param\n",
    "    Outputs\n",
    "        rmse            : root mean square error\n",
    "        mape            : mean absolute percentage error\n",
    "        est             : predictions\n",
    "    '''\n",
    "    # Create the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(x_train_scaled.shape[1],1)))\n",
    "    model.add(Dropout(dropout_prob)) # Add dropout with a probability of 0.5\n",
    "    model.add(LSTM(units=lstm_units))\n",
    "    model.add(Dropout(dropout_prob)) # Add dropout with a probability of 0.5\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile and fit the LSTM network\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    model.fit(x_train_scaled, y_train_scaled, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # Do prediction\n",
    "    est_scaled = model.predict(x_cv_scaled)\n",
    "    est = (est_scaled * np.array(std_cv_list).reshape(-1,1)) + np.array(mu_cv_list).reshape(-1,1)\n",
    "    \n",
    "    # Calculate RMSE and MAPE\n",
    "#     print(\"x_cv_scaled = \" + str(x_cv_scaled))\n",
    "#     print(\"est_scaled = \" + str(est_scaled))\n",
    "#     print(\"est = \" + str(est))\n",
    "    rmse = math.sqrt(mean_squared_error(y_cv, est))\n",
    "    mape = get_mape(y_cv, est)\n",
    "    \n",
    "    return rmse, mape, est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(stk_path, sep = \",\")\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df.loc[:, 'Date'] = pd.to_datetime(df['Date'],format='%Y-%m-%d')\n",
    "\n",
    "# Change all column headings to be lower case, and remove spacing\n",
    "df.columns = [str(x).lower().replace(' ', '_') for x in df.columns]\n",
    "\n",
    "# Get month of each sample\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "# Sort by datetime\n",
    "df.sort_values(by='date', inplace=True, ascending=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot adjusted close over time\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "\n",
    "ax = df.plot(x='date', y='adj_close', style='b-', grid=True)\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train, dev and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use lags up to N number of days to use as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get sizes of each of the datasets\n",
    "num_cv = int(cv_size*len(df))\n",
    "num_test = int(test_size*len(df))\n",
    "num_train = len(df) - num_cv - num_test\n",
    "print(\"num_train = \" + str(num_train))\n",
    "print(\"num_cv = \" + str(num_cv))\n",
    "print(\"num_test = \" + str(num_test))\n",
    "\n",
    "# Split into train, cv, and test\n",
    "train = df[:num_train][['date', 'adj_close']]\n",
    "cv = df[num_train:num_train+num_cv][['date', 'adj_close']]\n",
    "train_cv = df[:num_train+num_cv][['date', 'adj_close']]\n",
    "test = df[num_train+num_cv:][['date', 'adj_close']]\n",
    "\n",
    "print(\"train.shape = \" + str(train.shape))\n",
    "print(\"cv.shape = \" + str(cv.shape))\n",
    "print(\"train_cv.shape = \" + str(train_cv.shape))\n",
    "print(\"test.shape = \" + str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Converting dataset into x_train and y_train\n",
    "# Here we only scale the train dataset, and not the entire dataset to prevent information leak\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(np.array(train['adj_close']).reshape(-1,1))\n",
    "print(\"scaler.mean_ = \" + str(scaler.mean_))\n",
    "print(\"scaler.var_ = \" + str(scaler.var_))\n",
    "\n",
    "# Split into x and y\n",
    "x_train_scaled, y_train_scaled = get_x_y(train_scaled, N, N)\n",
    "print(\"x_train_scaled.shape = \" + str(x_train_scaled.shape)) # (446, 7, 1)\n",
    "print(\"y_train_scaled.shape = \" + str(y_train_scaled.shape)) # (446, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the cv dataset\n",
    "# Split into x and y\n",
    "x_cv_scaled, y_cv, mu_cv_list, std_cv_list = get_x_scaled_y(np.array(train_cv['adj_close']).reshape(-1,1), N, num_train)\n",
    "print(\"x_cv_scaled.shape = \" + str(x_cv_scaled.shape))\n",
    "print(\"y_cv.shape = \" + str(y_cv.shape))\n",
    "print(\"len(mu_cv_list) = \" + str(len(mu_cv_list)))\n",
    "print(\"len(std_cv_list) = \" + str(len(std_cv_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we scale the train_cv set, for the final model\n",
    "scaler_final = StandardScaler()\n",
    "train_cv_scaled_final = scaler_final.fit_transform(np.array(train_cv['adj_close']).reshape(-1,1))\n",
    "print(\"scaler_final.mean_ = \" + str(scaler_final.mean_))\n",
    "print(\"scaler_final.var_ = \" + str(scaler_final.var_))\n",
    "\n",
    "# # Scale the test dataset\n",
    "# x_test_scaled, y_test, mu_test_list, std_test_list = get_x_scaled_y(np.array(df['adj_close']).reshape(-1,1), N, num_train+num_cv)\n",
    "# print(\"x_test_scaled.shape = \" + str(x_test_scaled.shape))\n",
    "# print(\"y_test.shape = \" + str(y_test.shape))\n",
    "# print(\"len(mu_test_list) = \" + str(len(mu_test_list)))\n",
    "# print(\"len(std_test_list) = \" + str(len(std_test_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and fit the LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(x_train_scaled.shape[1],1)))\n",
    "model.add(Dropout(dropout_prob)) # Add dropout with a probability of 0.5\n",
    "model.add(LSTM(units=lstm_units))\n",
    "model.add(Dropout(dropout_prob)) # Add dropout with a probability of 0.5\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "model.fit(x_train_scaled, y_train_scaled, epochs=epochs, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot model and save to file\n",
    "from IPython.display import SVG\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "plot_model(model, to_file='model_v4a.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Do prediction\n",
    "est_scaled = model.predict(x_cv_scaled)\n",
    "est = (est_scaled * np.array(std_cv_list).reshape(-1,1)) + np.array(mu_cv_list).reshape(-1,1)\n",
    "print(\"est.shape = \" + str(est.shape))\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_bef_tuning = math.sqrt(mean_squared_error(y_cv, est))\n",
    "print(\"RMSE = %0.3f\" % rmse_bef_tuning)\n",
    "\n",
    "# Calculate MAPE\n",
    "mape_pct_bef_tuning = get_mape(y_cv, est)\n",
    "print(\"MAPE = %0.3f%%\" % mape_pct_bef_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot adjusted close over time\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "\n",
    "est_df = pd.DataFrame({'est': est.reshape(-1), \n",
    "                       'y_cv': y_cv.reshape(-1),\n",
    "                       'date': cv['date']})\n",
    "\n",
    "ax = train.plot(x='date', y='adj_close', style='b-', grid=True)\n",
    "ax = cv.plot(x='date', y='adj_close', style='y-', grid=True, ax=ax)\n",
    "ax = test.plot(x='date', y='adj_close', style='g-', grid=True, ax=ax)\n",
    "ax = est_df.plot(x='date', y='est', style='r-', grid=True, ax=ax)\n",
    "ax.legend(['train', 'dev', 'test', 'est'])\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning N (no. of days to use as features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_label = 'N'\n",
    "param_list = range(3, 60)\n",
    "\n",
    "error_rate = {param_label: [], 'rmse': [], 'mape_pct': []}\n",
    "tic = time.time()\n",
    "for param in tqdm_notebook(param_list):\n",
    "    \n",
    "    # Split train into x and y\n",
    "    x_train_scaled, y_train_scaled = get_x_y(train_scaled, param, param)\n",
    "\n",
    "    # Split cv into x and y\n",
    "    x_cv_scaled, y_cv, mu_cv_list, std_cv_list = get_x_scaled_y(np.array(train_cv['adj_close']).reshape(-1,1), param, num_train)\n",
    "    \n",
    "    # Train, predict and eval model\n",
    "    rmse, mape, _ = train_pred_eval_model(x_train_scaled, \\\n",
    "                                          y_train_scaled, \\\n",
    "                                          x_cv_scaled, \\\n",
    "                                          y_cv, \\\n",
    "                                          mu_cv_list, \\\n",
    "                                          std_cv_list, \\\n",
    "                                          lstm_units=lstm_units, \\\n",
    "                                          dropout_prob=dropout_prob, \\\n",
    "                                          optimizer=optimizer, \\\n",
    "                                          epochs=epochs, \\\n",
    "                                          batch_size=batch_size)\n",
    "    \n",
    "    # Collect results\n",
    "    error_rate[param_label].append(param)\n",
    "    error_rate['rmse'].append(rmse)\n",
    "    error_rate['mape_pct'].append(mape)\n",
    "    \n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "toc = time.time()\n",
    "print(\"Minutes taken = \" + str((toc-tic)/60.0))\n",
    "error_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot RMSE \n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "\n",
    "ax = error_rate.plot(x='N', y='rmse', style='bx-', grid=True)\n",
    "ax = error_rate.plot(x='N', y='mape_pct', style='rx-', grid=True, ax=ax)\n",
    "ax.set_xlabel(\"N\")\n",
    "ax.set_ylabel(\"RMSE/MAPE(%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get optimum value for param\n",
    "temp = error_rate[error_rate['rmse'] == error_rate['rmse'].min()]\n",
    "N_opt = temp['N'].values[0]\n",
    "print(\"min RMSE = %0.3f\" % error_rate['rmse'].min())\n",
    "print(\"min MAPE = %0.3f%%\" % error_rate['mape_pct'].min())\n",
    "print(\"optimum \" + param_label + \" = \" + str(N_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning model - epochs and batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_label = 'epochs'\n",
    "param_list = [1, 10, 20, 30, 40, 50]\n",
    "\n",
    "param2_label = 'batch_size'\n",
    "param2_list = [8, 16, 32, 64, 128]\n",
    "\n",
    "# Split train into x and y\n",
    "x_train_scaled, y_train_scaled = get_x_y(train_scaled, N_opt, N_opt)\n",
    "\n",
    "# Split cv into x and y\n",
    "x_cv_scaled, y_cv, mu_cv_list, std_cv_list = get_x_scaled_y(np.array(train_cv['adj_close']).reshape(-1,1), N_opt, num_train)\n",
    "\n",
    "error_rate = {param_label: [], param2_label: [], 'rmse': [], 'mape_pct': []}\n",
    "tic = time.time()\n",
    "for param in tqdm_notebook(param_list):\n",
    "    \n",
    "    for param2 in tqdm_notebook(param2_list):\n",
    "    \n",
    "        # Train, predict and eval model\n",
    "        rmse, mape, _ = train_pred_eval_model(x_train_scaled, \\\n",
    "                                              y_train_scaled, \\\n",
    "                                              x_cv_scaled, \\\n",
    "                                              y_cv, \\\n",
    "                                              mu_cv_list, \\\n",
    "                                              std_cv_list, \\\n",
    "                                              lstm_units=lstm_units, \\\n",
    "                                              dropout_prob=dropout_prob, \\\n",
    "                                              optimizer=optimizer, \\\n",
    "                                              epochs=param, \\\n",
    "                                              batch_size=param2)\n",
    "    \n",
    "        # Collect results\n",
    "        error_rate[param_label].append(param)\n",
    "        error_rate[param2_label].append(param2)\n",
    "        error_rate['rmse'].append(rmse)\n",
    "        error_rate['mape_pct'].append(mape)\n",
    "    \n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "toc = time.time()\n",
    "print(\"Minutes taken = \" + str((toc-tic)/60.0))\n",
    "error_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot performance versus params\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "temp = error_rate[error_rate[param2_label]==param2_list[0]]\n",
    "ax = temp.plot(x=param_label, y='rmse', style='bs-', grid=True)\n",
    "legend_list = [param2_label + '_' + str(param2_list[0])]\n",
    "\n",
    "color_list = ['r', 'g', 'k', 'y', 'm', 'c', '0.75']\n",
    "for i in range(1,len(param2_list)):\n",
    "    temp = error_rate[error_rate[param2_label]==param2_list[i]]\n",
    "    ax = temp.plot(x=param_label, y='rmse', color=color_list[i%len(color_list)], marker='s', grid=True, ax=ax)\n",
    "    legend_list.append(param2_label + '_' + str(param2_list[i]))\n",
    "\n",
    "ax.set_xlabel(param_label)\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.legend(legend_list, loc='center left', bbox_to_anchor=(1.0, 0.5)) # positions legend outside figure\n",
    "# ax.set_xlim([10, 50])\n",
    "# ax.set_ylim([0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2\n",
    "temp = error_rate[error_rate['rmse'] == error_rate['rmse'].min()]\n",
    "epochs_opt = temp[param_label].values[0]\n",
    "batch_size_opt = temp[param2_label].values[0]\n",
    "print(\"min RMSE = %0.3f\" % error_rate['rmse'].min())\n",
    "print(\"min MAPE = %0.3f%%\" % error_rate['mape_pct'].min())\n",
    "print(\"optimum \" + param_label + \" = \" + str(epochs_opt))\n",
    "print(\"optimum \" + param2_label + \" = \" + str(batch_size_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning model - LSTM units and dropout prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_label = 'lstm_units'\n",
    "param_list = [10, 50, 64, 128]\n",
    "\n",
    "param2_label = 'dropout_prob'\n",
    "param2_list = [0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "error_rate = {param_label: [], param2_label: [], 'rmse': [], 'mape_pct': []}\n",
    "tic = time.time()\n",
    "for param in tqdm_notebook(param_list):\n",
    "    \n",
    "    for param2 in tqdm_notebook(param2_list):\n",
    "    \n",
    "        # Train, predict and eval model\n",
    "        rmse, mape, _ = train_pred_eval_model(x_train_scaled, \\\n",
    "                                              y_train_scaled, \\\n",
    "                                              x_cv_scaled, \\\n",
    "                                              y_cv, \\\n",
    "                                              mu_cv_list, \\\n",
    "                                              std_cv_list, \\\n",
    "                                              lstm_units=param, \\\n",
    "                                              dropout_prob=param2, \\\n",
    "                                              optimizer=optimizer, \\\n",
    "                                              epochs=epochs_opt, \\\n",
    "                                              batch_size=batch_size_opt)\n",
    "    \n",
    "        # Collect results\n",
    "        error_rate[param_label].append(param)\n",
    "        error_rate[param2_label].append(param2)\n",
    "        error_rate['rmse'].append(rmse)\n",
    "        error_rate['mape_pct'].append(mape)\n",
    "    \n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "toc = time.time()\n",
    "print(\"Minutes taken = \" + str((toc-tic)/60.0))\n",
    "error_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot performance versus params\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "temp = error_rate[error_rate[param2_label]==param2_list[0]]\n",
    "ax = temp.plot(x=param_label, y='rmse', style='bs-', grid=True)\n",
    "legend_list = [param2_label + '_' + str(param2_list[0])]\n",
    "\n",
    "color_list = ['r', 'g', 'k', 'y', 'm', 'c', '0.75']\n",
    "for i in range(1,len(param2_list)):\n",
    "    temp = error_rate[error_rate[param2_label]==param2_list[i]]\n",
    "    ax = temp.plot(x=param_label, y='rmse', color=color_list[i%len(color_list)], marker='s', grid=True, ax=ax)\n",
    "    legend_list.append(param2_label + '_' + str(param2_list[i]))\n",
    "\n",
    "ax.set_xlabel(param_label)\n",
    "ax.set_ylabel(\"RMSE\")\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "plt.legend(legend_list, loc='center left', bbox_to_anchor=(1.0, 0.5)) # positions legend outside figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2\n",
    "temp = error_rate[error_rate['rmse'] == error_rate['rmse'].min()]\n",
    "lstm_units_opt = temp[param_label].values[0]\n",
    "dropout_prob_opt = temp[param2_label].values[0]\n",
    "print(\"min RMSE = %0.3f\" % error_rate['rmse'].min())\n",
    "print(\"min MAPE = %0.3f%%\" % error_rate['mape_pct'].min())\n",
    "print(\"optimum \" + param_label + \" = \" + str(lstm_units_opt))\n",
    "print(\"optimum \" + param2_label + \" = \" + str(dropout_prob_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning model - optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_label = 'optimizer'\n",
    "param_list = ['adam', 'sgd', 'rmsprop', 'adagrad', 'adadelta', 'adamax', 'nadam']\n",
    "\n",
    "error_rate = {param_label: [], 'rmse': [], 'mape_pct': []}\n",
    "tic = time.time()\n",
    "for param in tqdm_notebook(param_list):\n",
    "   \n",
    "    # Train, predict and eval model\n",
    "    rmse, mape, _ = train_pred_eval_model(x_train_scaled, \\\n",
    "                                          y_train_scaled, \\\n",
    "                                          x_cv_scaled, \\\n",
    "                                          y_cv, \\\n",
    "                                          mu_cv_list, \\\n",
    "                                          std_cv_list, \\\n",
    "                                          lstm_units=lstm_units_opt, \\\n",
    "                                          dropout_prob=dropout_prob_opt, \\\n",
    "                                          optimizer=param, \\\n",
    "                                          epochs=epochs_opt, \\\n",
    "                                          batch_size=batch_size_opt)\n",
    "    \n",
    "    # Collect results\n",
    "    error_rate[param_label].append(param)\n",
    "    error_rate['rmse'].append(rmse)\n",
    "    error_rate['mape_pct'].append(mape)\n",
    "    \n",
    "error_rate = pd.DataFrame(error_rate)\n",
    "toc = time.time()\n",
    "print(\"Minutes taken = \" + str((toc-tic)/60.0))\n",
    "error_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot RMSE \n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "\n",
    "ax = error_rate.plot(x='optimizer', y='rmse', style='bx-', grid=True)\n",
    "ax = error_rate.plot(x='optimizer', y='mape_pct', style='rx-', grid=True, ax=ax)\n",
    "ax.set_xticklabels(param_list)\n",
    "ax.set_xlabel(\"Optimizer\")\n",
    "ax.set_ylabel(\"RMSE/MAPE(%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get optimum value for param and param2\n",
    "temp = error_rate[error_rate['rmse'] == error_rate['rmse'].min()]\n",
    "optimizer_opt = temp[param_label].values[0]\n",
    "print(\"min RMSE = %0.3f\" % error_rate['rmse'].min())\n",
    "print(\"min MAPE = %0.3f%%\" % error_rate['mape_pct'].min())\n",
    "print(\"optimum \" + param_label + \" = \" + str(optimizer_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = {'param': ['N', 'lstm_units', 'dropout_prob', 'optimizer', 'epochs', 'batch_size', 'rmse', 'mape_pct'],\n",
    "     'original': [N, lstm_units, dropout_prob, optimizer, epochs, batch_size, rmse_bef_tuning, mape_pct_bef_tuning],\n",
    "     'after_tuning': [N_opt, lstm_units_opt, dropout_prob_opt, optimizer_opt, epochs_opt, batch_size_opt, error_rate['rmse'].min(), error_rate['mape_pct'].min()]}\n",
    "tuned_params = pd.DataFrame(d)\n",
    "tuned_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split train_cv into x and y\n",
    "x_train_cv_scaled, y_train_cv_scaled = get_x_y(train_cv_scaled_final, N_opt, N_opt)\n",
    "\n",
    "# Split test into x and y\n",
    "x_test_scaled, y_test, mu_test_list, std_test_list = get_x_scaled_y(np.array(df['adj_close']).reshape(-1,1), N_opt, num_train+num_cv)\n",
    "\n",
    "# Train, predict and eval model\n",
    "rmse, mape, est = train_pred_eval_model(x_train_cv_scaled, \\\n",
    "                                        y_train_cv_scaled, \\\n",
    "                                        x_test_scaled, \\\n",
    "                                        y_test, \\\n",
    "                                        mu_test_list, \\\n",
    "                                        std_test_list, \\\n",
    "                                        lstm_units=lstm_units_opt, \\\n",
    "                                        dropout_prob=dropout_prob_opt, \\\n",
    "                                        optimizer=optimizer_opt, \\\n",
    "                                        epochs=epochs_opt, \\\n",
    "                                        batch_size=batch_size_opt)\n",
    "\n",
    "# Calculate RMSE\n",
    "print(\"RMSE on test set = %0.3f\" % rmse)\n",
    "\n",
    "# Calculate MAPE\n",
    "print(\"MAPE on test set = %0.3f%%\" % mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot adjusted close over time\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "\n",
    "est_df = pd.DataFrame({'est': est.reshape(-1), \n",
    "                       'date': df[num_train+num_cv:]['date']})\n",
    "\n",
    "ax = train.plot(x='date', y='adj_close', style='b-', grid=True)\n",
    "ax = cv.plot(x='date', y='adj_close', style='y-', grid=True, ax=ax)\n",
    "ax = test.plot(x='date', y='adj_close', style='g-', grid=True, ax=ax)\n",
    "ax = est_df.plot(x='date', y='est', style='r-', grid=True, ax=ax)\n",
    "ax.legend(['train', 'dev', 'test', 'predictions'])\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot adjusted close over time, for test set only\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "ax = train.plot(x='date', y='adj_close', style='b-', grid=True)\n",
    "ax = cv.plot(x='date', y='adj_close', style='y-', grid=True, ax=ax)\n",
    "ax = test.plot(x='date', y='adj_close', style='g-', grid=True, ax=ax)\n",
    "ax = est_df.plot(x='date', y='est', style='r-', grid=True, ax=ax)\n",
    "ax.legend(['train', 'dev', 'test', 'predictions'])\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"USD\")\n",
    "ax.set_xlim([date(2018, 4, 1), date(2018, 11, 30)])\n",
    "ax.set_ylim([130, 155])\n",
    "ax.set_title(\"Zoom in to test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot adjusted close over time, only for test set\n",
    "rcParams['figure.figsize'] = 10, 8 # width 10, height 8\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "\n",
    "ax = test.plot(x='date', y='adj_close', style='gx-', grid=True)\n",
    "ax = est_df.plot(x='date', y='est', style='rx-', grid=True, ax=ax)\n",
    "ax.legend(['test', 'predictions using lstm'], loc='upper left')\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"USD\")\n",
    "ax.set_xlim([date(2018, 4, 23), date(2018, 11, 23)])\n",
    "ax.set_ylim([130, 155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "test_lstm = est_df\n",
    "test_lstm.to_csv(\"./out/test_lstm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings\n",
    "* On the test set, the RMSE is 1.164 and MAPE is 0.583% using N_opt=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
